# Instaclustr backup-restore

image:https://img.shields.io/maven-central/v/com.instaclustr/instaclustr-backup-restore.svg?label=Maven%20Central[link=https://search.maven.org/search?q=g:%22com.instaclustr%22%20AND%20a:%22instaclustr-backup-restore%22]

image:https://circleci.com/gh/instaclustr/cassandra-backup.svg?style=svg["Instaclustr",link="https://circleci.com/gh/instaclustr/cassandra-backup"]

This repository is home of backup and restoration tool from Instaclustr.

The tool is able to perform these operations:

* backup of SSTables
* restore of SSTables
* backup of commit logs
* restore of commit logs

## Usage

After this project is built, the binary is in `target` and it is
called `instaclustr-backup-restore-(version).jar`. This binary is all you need to backup / restore.
It is command line application, invoke it without any arguments to see help. You can invoke
`help backup` for `backup` command, for example.

----
java -jar target/instaclustr-backup-restore.jar
Missing required subcommand.
Usage: <main class> [-V] COMMAND
  -V, --version   print version information and exit
Commands:
  backup             Take a snapshot of this nodes Cassandra data and upload it
                       to remote storage. Defaults to a snapshot of all
                       keyspaces and their column families, but may be
                       restricted to specific keyspaces or a single
                       column-family.
  restore            Restore the Cassandra data on this node to a specified
                       point-in-time.
  commitlog-backup   Upload archived commit logs to remote storage.
  commitlog-restore  Restores archived commit logs to node.

----

## Examples

All commands should be preceded with `java -jar /path/to/backup/tool.jar`

### Example of `backup`

This command with copy over all SSTables to remote location. It is possible to choose also location
in cloud. For backup, a node has to be up to back it up. There is possibility to backup also offline node,
please consult `help` of `backup` command to know details.

----
$ backup --jmx-service 127.0.0.1:7199 \
  --storage-location=file:///destination/to/backup/cluster-name/dc-name/node-id \
  --data-directory=/my/installation/of/cassandra/data
----

If you want to upload SSTables into AWS / GCP or Azure, just change `file://` protocol to either `s3`,
`gcp` or `azure`. The first part of the path is the bucket you want to upload files to, for `s3`,
it would be like `s3://bucket-for-my-cluster/cluster-name/dc-name/node-id`. If you want to use different
cloud, just change the protocol respectively.

If a bucket does not exist, it will be automatically created.

### Example of `commitlog-backup`

You can backup commit logs as well. Example of commit log backup is like the following:

----
$ commitlog-backup \
  --storage-location=file:///destination/to/backup/cluster-name/dc-name/node-id, \
  --data-directory=/my/installation/of/cassandra/data
----

Note that there is not any need to specify jmx-service because it is not needed. JMX is needed
for taking snapshots, but here we do not take any.

### Example of `restore`

The restoration of a node is achieved by following parameters

----
$ restore --data-directory=/my/installation/of/restored-cassandra/data \
          --config-directory=/my/installation/of/restored-cassandra/conf \
          --snapshot-tag=stefansnapshot" \
          --storage-location=s3://bucket-name/cluster-name/dc-name/node-id \
          --update-cassandra-yaml=true"
----

Notice few things here:

* `--snapshot-tag` is specified. Normally, when snapshot name is not used upon backup, there
is a snapshot taken of some generated name. You would have to check the name of a snapshot in
backup location to specify it yourself, so it is better to specify that beforehand and you just
reference it.
* `--update-cassandra-yaml` is set to true, this will automatically set `initial_tokens` in `cassandra.yaml` for
restored node. If it is false, you would have to set it up yourself, copying the content of tokens file
in backup directory, under `tokens` directory.

### Example of `commitlog-restore`

The restoration of commit logs is done e.g. like this:

----
$ commitlog-restore --data-directory=/my/installation/of/restored-cassandra/data
                    --config-directory=/my/installation/of/restored-cassandra/conf
                    --storage-location=s3://bucket-name/cluster-name/dc-name/node-id
                    --commitlog-download-dir=/dir/where/commitlogs/are/downloaded
                    --timestamp-end=unix_timestamp_of_last_transaction_to_replay
----

The commitlog restorations is driven by Cassandra's `commitlog_archiving.properties` file. This
tool will generate such file into node's `conf` directory so it will be read upon nodes start.

After a node is restored in this manner, one has to *delete* `commitlog_archiving.properties` file
in order to prevent commitlog replay by accident again if a node is restarted.

----
restore_directories=/home/smiklosovic/dev/instaclustr-backup-restore/target/commitlog_download_dir
restore_point_in_time=2020\:01\:13 11\:32\:51
restore_command=cp -f %from %to
----

## Credentials for backup and restore from a cloud

If you deal with a cloud, you have to setup credentials to do so. The setup varies from cloud to cloud.

### S3

For S3, you have to set `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` as environment variables
or `aws.accessKeyId` and `aws.secretKey` as system properties or you put them into ~/.aws/credentials.
S3 backup module is receptive to `AWS_REGION` as well as `AWS_ENDPOINT` environment variables.

As of release `1.1.3` the aws-sdk-java library is capable of using
https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html[IAM Roles for Service Accounts].
IRSA allows you to grant an AWS IAM Role to a Kubernetes Service Account without mounting secrets,
passing environment variables or using node profiles.

### Azure

For Azure, you need to set `AZURE_STORAGE_ACCOUNT` and `AZURE_STORAGE_KEY` environment variables.

### GCP

For GCP you have to use `GOOGLE_APPLICATION_CREDENTIALS` environment variable.

## Backup resolution for file:// protocol

In every case, file has to start with full path (file:///, three slashes).
File location does not have a notion of a _bucket_ but we are using it here
regardless, it the following examples, _bucket_ will be _a_.

If you do not specify full path (e.g. like it is shown in the last example),
the path will be the directory from which you are invoking this tool _plus_ bucket ("a" in our case).

It does not matter you put slash at the end of whole location, it will be removed.

.file path resolution
|===
|storage location |path

|file:///tmp/some/path/a/b/c/d
|/tmp/some/path/a

|file:///tmp/a/b/c/d
|/tmp/a

|file:///a/b/c/d
|$(pwd)/a
|===
## Build

You build this tool by invoking:

----
$ ./mvnw clean install
----

## Tests

There are end-to-end tests which are testing all GCP, Azure and S3 integration as well
as integration with Kubernetes when it comes to credential fetching.

There are these test groups / profiles:

* azureTests
* googleTest
* s3Tests
* cloudTests - runs tests which will be using cloud "buckets" for backup / restore
* k8sTest - same as `cloudTest` above but credentials will be fetched from Kubernetes

The anatomy of a test is like the following;

* start Cassandra as part of a test (runs locally)
* insert data into Cassandra and backup them to some cloud
* stop Cassandra
* download files we just backed up into a directory
* start another Cassandra instance (also locally) which will have data directory pointing to directory we downloaded data into
* verify that the restoration is correct
* stop second Cassandra

There is not any need to create buckets in a cloud beforehand as they will be created and deleted
as part of a test itself automatically, per cloud provider.

If this test is "Kubernetes-aware", before every test, credentials are created as a Secret
which will be used by backup / restore tooling during a test. We are simulating here that
this tooling can be easily embedded into e.g. a Cassandra Sidecar (part of Cassandra operator).
We are avoiding the need to specify credentials upfront when Kubernetes pod is starting as a part
of that spec by dynamically fetching all credentials from a Secret which name is passed to a
backup request and it is read every time. The side-effect of this is that we can change our credentials
without restarting a pod to re-read them because they will be read dynamically upon every backup request.

Cloud tests are executed like:

----
$ mvn clean install -PcloudTests
----

Kubernetes tests are executed like:
----
$ mvn clean install -Pk8sTests
----

You have to specify these system properties to run these tests succesfully:

----
-Dawsaccesskeyid={your aws access key id}
-Dawssecretaccesskey={your aws secret access key}
-Dgoogle.application.credentials={path to google application credentials file on local disk}
-Dazurestorageaccount={your azure storage account}
-Dazurestoragekey={your azure storage key}
----

Please see https://www.instaclustr.com/support/documentation/announcements/instaclustr-open-source-project-status/ for Instaclustr support status of this project
